{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOis9Zs3uJVvCviQGRU8m4U"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"nI1DmiWqIrqY"},"outputs":[],"source":["# vinai/PhoGPT-4B-Chat-v0.1"]},{"cell_type":"code","source":["# !git clone https://huggingface.co/vinai/PhoGPT-4B-Chat-v0.1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xMFoRMBQJHG5","executionInfo":{"status":"ok","timestamp":1708694973224,"user_tz":-420,"elapsed":238978,"user":{"displayName":"Tùng Thanh","userId":"03862029645026081820"}},"outputId":"a232e06f-e659-4712-a75b-767c28009bea"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'PhoGPT-4B-Chat-v0.1'...\n","remote: Enumerating objects: 43, done.\u001b[K\n","remote: Counting objects: 100% (40/40), done.\u001b[K\n","remote: Compressing objects: 100% (40/40), done.\u001b[K\n","remote: Total 43 (delta 12), reused 0 (delta 0), pack-reused 3\u001b[K\n","Unpacking objects: 100% (43/43), 265.51 KiB | 494.00 KiB/s, done.\n","fatal: cannot exec '/content/drive/MyDrive/Colab Notebooks/PhoGPT-4B-Chat-v0.1/.git/hooks/post-checkout': Permission denied\n","Encountered 1 file(s) that may not have been copied correctly on Windows:\n","\tpytorch_model.bin\n","\n","See: `git lfs help smudge` for more details.\n"]}]},{"cell_type":"code","source":["!pip install -q transformers einops torch accelerate"],"metadata":{"id":"7oat3P2HJPyl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Model: vinai/PhoGPT-4B-Chat-v0.1\n","\n","* Type: Instruction following & Chat\n","* Model Size: 3.7B\n","* Context length: 8192\n","* Vocab size: 20K\n","* Training data size: 70K instructional prompt and response pairs & 290K conversations\n","* Note: PROMPT_TEMPLATE = \"### Câu hỏi: {instruction}\\n### Trả lời:\""],"metadata":{"id":"l0bnET6FJqd3"}},{"cell_type":"code","source":["# coding: utf8\n","import torch, accelerate,transformers, einops\n","from transformers import AutoConfig, AutoModelForCausalLM, AutoTokenizer\n","\n","# model_path = \"PhoGPT-4B-Chat-v0.1\"\n","model_path = \"PhoGPT-4B-Chat-v01\"\n","\n","config = AutoConfig.from_pretrained(model_path, trust_remote_code=True)\n","config.init_device = \"cuda\"\n","\n","model = AutoModelForCausalLM.from_pretrained(model_path, config=config, torch_dtype=torch.bfloat16, trust_remote_code=True, use_auth_token=None)\n","# If your GPU does not support bfloat16:\n","# model = AutoModelForCausalLM.from_pretrained(model_path, config=config, torch_dtype=torch.float16, trust_remote_code=True)\n","model.eval()\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n","\n","PROMPT_TEMPLATE = \"### Câu hỏi: {instruction}\\n### Trả lời:\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JQDLeO1mJRHU","executionInfo":{"status":"ok","timestamp":1708696011589,"user_tz":-420,"elapsed":114039,"user":{"displayName":"Tùng Thanh","userId":"03862029645026081820"}},"outputId":"a64ac449-c6d2-4d25-e50c-6a242cee18b0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  return self.fget.__get__(instance, owner)()\n"]}]},{"cell_type":"code","source":["def model_generator(model, instruction):\n","  input_prompt = PROMPT_TEMPLATE.format_map({\"instruction\": instruction})\n","  input_ids = tokenizer(input_prompt, return_tensors=\"pt\")\n","\n","  outputs = model.generate(\n","  inputs=input_ids[\"input_ids\"].to(\"cuda\"),\n","  # attention_mask=input_ids[\"attention_mask\"].to(\"cuda\"),\n","  do_sample=True,\n","  temperature=1.0,\n","  top_k=50,\n","  top_p=0.9,\n","  max_new_tokens=1024,\n","  eos_token_id=tokenizer.eos_token_id,\n","  pad_token_id=tokenizer.pad_token_id,\n","  # return_dict_in_generate=True, output_scores=True\n","  # output_hidden_states = True,\n","  )\n","\n","  response = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n","  response = response.split(\"### Trả lời:\")[1]\n","  return response"],"metadata":{"id":"IliTR9IDJeKd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Some instruction examples\n","# instruction = \"Viết bài văn nghị luận xã hội về {topic}\"\n","# instruction = \"Viết bản mô tả công việc cho vị trí {job_title}\"\n","# instruction = \"Sửa lỗi chính tả:\\n{sentence_or_paragraph}\"\n","# instruction = \"Dựa vào văn bản sau đây:\\n{text}\\nHãy trả lời câu hỏi: {question}\"\n","# instruction = \"Tóm tắt văn bản:\\n{text}\"\n","\n","# instruction = \"Viết bài văn nghị luận xã hội về an toàn giao thông\"\n","# instruction = \"Sửa lỗi chính tả:\\nTriệt phá băng nhóm kướp ô tô, sử dụng \\\"vũ khí nóng\\\"\"\n","\n","# instruction = \"Hãy đưa ra 10 ý tưởng về marketing bán hàng và các bước để thực hiện những ý tưởng đó\""],"metadata":{"id":"GhhoRMe4Kh0I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# model_path = \"PhoGPT-4B-Chat-v0.1\"\n","instruction = \"em tên là gì? em nhà ở đâu thế? sở thích của em là gì?\"\n","print(model_generator(model, instruction))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"60laOffEODoR","executionInfo":{"status":"ok","timestamp":1708696154206,"user_tz":-420,"elapsed":6562,"user":{"displayName":"Tùng Thanh","userId":"03862029645026081820"}},"outputId":"7132329c-1676-4e81-cad4-4b1c895bceac"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Em tên là Anna, và em sống ở thành phố New York. Còn sở thích của em là đọc sách, xem phim và chơi bóng rổ.\n"]}]}]}